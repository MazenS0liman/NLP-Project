# Arabic Transcript Analysis Pipeline ğŸš€

This repository contains the code and results from **Milestone 1** of the CSEN1076: Natural Language Processing and Information Retrieval course. Our goal was to build a preprocessing and analysis pipeline for Arabic YouTube transcripts (ElDa7ee7 channel) and explore various NLP tasks and visualizations.

## ğŸ“ Project Structure

* `data/` â€“ Raw and cleaned transcript files ğŸ—‚ï¸
* `notebooks/` â€“ Jupyter notebooks for preprocessing and analysis ğŸ““
* `models/` â€“ Saved Hugging Face model checkpoints ğŸ’¾

## ğŸ”„ Preprocessing Pipeline

1. **ğŸ§¹ Tidying Up**

   * Removed timestamps and non-text noise (hashtags, emojis, etc.) ğŸ—‘ï¸
   * Attempted spelling correction with Ghalatawi (did not yield expected improvements) ğŸ“
2. **ğŸ”  Tokenization & Sentence Splitting**

   * Applied SBERT embeddings + cosine similarity threshold to segment transcripts into coherent sentences âœ‚ï¸
3. **ğŸŒ Language Translation**

   * Tried translating Egyptian Arabic to English for comparative analysis (translation inconsistencies limited its utility) ğŸ”„
4. **âœ‚ï¸ Stopword Removal & Dediacritization**

   * Combined NLTK, TASHAPHYNE, and custom stopword lists ğŸ› ï¸
   * Removed diacritics to normalize text ğŸ”¤

## ğŸ§  NLP Analysis Tasks

* **ğŸ˜ŠğŸ˜  Sentiment Analysis**
  Used `bert-base-arabic-camel-msa-sentiment` from CAMeL Lab. Model over-classified negative labels due to dialect-specific word usage.

* **ğŸ“š Topic Classification**
  Fine-tuned `bert-base-arabertv2` from Aubmind Lab on multiple categories (culture, politics, tech, etc.). Frequent misclassification as "religion" due to common religious terms.

* **ğŸ¤¨ Sarcasm Detection**
  Fine-tuned on Twitter dataset; performance was limited by dataset size and dialectal variation.

* **ğŸ“° Text Summarization**
  Evaluated `mbert2mbert-arabic-text-summarization`; produced hallucinations on long transcripts.

## ğŸ“Š Visualization & Insights

* **ğŸ“‘ Basic Statistics**
  Computed word counts, unique tokens, sentence counts, and TFâ€“IDF scores.

* **â˜ï¸ Word Cloud**
  Generated before/after stopword removal using `word_cloud`, `arabic-reshaper`, and `python-bidi`.

* **ğŸ”¢ Most Frequent N-grams**
  Identified top 3-grams; revealed highly repetitive filler phrases acting as outliers.

* **ğŸš« Outlier Removal & ğŸ·ï¸ NER**
  Removed common fillers; applied CAMeL Labs NER to extract top nouns (e.g., historical entities, country names).

* **ğŸ”— Content Similarity**
  Built cosine similarity matrix across videos; found limited overlap with occasional thematic repeats.

* **â¤ï¸ğŸ‘ï¸ Engagement Analysis**

  * **Likes vs. Category** â€“ Political videos showed high average likes; small sample sizes noted.
  * **Likes vs. Description Length** â€“ Positive correlation between word count and likes.
  * **Views vs. Category** â€“ Politics and Culture attracted higher views.
  * **Views vs. Transcript Length** â€“ Longer transcripts correlated with more views.
  * **Views vs. Sarcasm Frequency** â€“ Spikes in views for episodes with very high sarcasm levels.

## ğŸš€ Potential Follow-Up Tasks

* Regression modeling to predict views/likes from transcript features ğŸ“ˆ
* Improved dialectal sentiment and sarcasm models with larger labeled data ğŸ—£ï¸
* Topic modeling (LDA) on cleaned transcripts ğŸ§
* Fine-tuning sequence-to-sequence summarization on domain-specific corpus âœï¸

## ğŸ¯ Conclusion

This milestone demonstrated the challenges of Arabic NLP (dialectal variance, model biases) and provided foundational insights into ElDa7ee7â€™s content and audience engagement. The pipeline is modular and can be extended for downstream predictive and generative tasks.

---

*Prepared by Mazen Soliman & Mohamed Shamekh* ğŸ˜Š
