{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a82d72",
   "metadata": {},
   "source": [
    "# <p style=\"padding:50px;background-color:#06402B;margin:0;color:#fafefe;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:100\">Experiment 1: COT Full Finetuned LlaMa vs COT Gemini</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43e04f",
   "metadata": {},
   "source": [
    "**Description:** This experiment is about comparing COT Finetuned LlaMa-3B-Instruct model and COT Google Gemini based on the SQUAD's validation dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b5eeb0",
   "metadata": {},
   "source": [
    "## <p style=\"padding:50px;background-color:#06402B;margin:0;color:#fafefe;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:100\">Imports</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d6cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import string\n",
    "import itertools\n",
    "\n",
    "from collections import Counter\n",
    "from typing import Callable, Dict\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Convert_system_message_to_human will be deprecated!\"\n",
    ")\n",
    "\n",
    "# LangChain components\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58bc17",
   "metadata": {},
   "source": [
    "## <p style=\"padding:50px;background-color:#06402B;margin:0;color:#fafefe;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:100\">RAG</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d20a0",
   "metadata": {},
   "source": [
    "### 1. Define Data Source Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "301b81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = Path(\"experiments/data/validation.json\")\n",
    "OUTPUT_FILE = Path(\"experiments/data/context.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f5a56",
   "metadata": {},
   "source": [
    "### 2. Define Extract Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4aa785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(input_path):\n",
    "    context_set = set()\n",
    "    with input_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            ctx = record.get(\"context\")\n",
    "            if ctx and ctx not in context_set:\n",
    "                context_set.add(ctx)\n",
    "                yield ctx\n",
    "\n",
    "def write_contexts_to_file(contexts, output_path):\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for i, ctx in enumerate(contexts, start=1):\n",
    "            f.write(ctx)\n",
    "            f.write(\"\\n\\n\")\n",
    "    print(f\"Wrote {i} contexts to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd38287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 2067 contexts to experiments\\data\\context.txt\n"
     ]
    }
   ],
   "source": [
    "contexts = extract(INPUT_FILE)\n",
    "write_contexts_to_file(contexts, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5aa06",
   "metadata": {},
   "source": [
    "### 3. Store Data in Qdrant DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39e7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b352b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fastembed_model():\n",
    "    return FastEmbedEmbeddings()\n",
    "\n",
    "def create_embeddings():\n",
    "    return get_fastembed_model()\n",
    "\n",
    "def load_text_files(txt_file: str) -> list[Document]:\n",
    "    text = Path(txt_file).read_text(encoding=\"utf-8\")\n",
    "    blocks = [blk.strip() for blk in text.split(\"\\n\\n\") if blk.strip()]\n",
    "    docs = []\n",
    "    for idx, blk in enumerate(blocks, start=1):\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=blk,\n",
    "                metadata={\n",
    "                    \"source\": Path(txt_file).name,\n",
    "                    \"block_index\": idx,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return docs\n",
    "\n",
    "def build_qdrant_index(docs: list[Document], embeddings):\n",
    "    return Qdrant.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        location=\":memory:\",\n",
    "        collection_name=\"text_chunks\",\n",
    "    )\n",
    "\n",
    "def generate_retriever(txt_dir: str = \"./data/all_contexts.txt\"):\n",
    "    raw_docs = load_text_files(txt_dir)\n",
    "    print(f\"Loaded {len(raw_docs)} documents from {txt_dir}\")\n",
    "    embeddings = create_embeddings()\n",
    "    vectorstore = build_qdrant_index(raw_docs, embeddings)\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5},\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230d14f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2067 documents from ./experiments/data/context.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "retriever = generate_retriever(txt_dir=\"./experiments/data/context.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f443ce",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc580108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mazen\\AppData\\Local\\Temp\\ipykernel_33904\\397147675.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Since its inception, ABC has had many affiliated stations, which include WABC-TV and WPVI-TV, the first two stations to carry the network's programming. As of March 2015[update], ABC has eight owned-and-operated stations, and current and pending affiliation agreements with 235 additional television stations encompassing 49 states, the District of Columbia, four U.S. possessions, Bermuda and Saba; this makes ABC the largest U.S. broadcast television network by total number of affiliates. The network has an estimated national reach of 96.26% of all households in the United States (or 300,794,157 Americans with at least one television set). relevant documents.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is ABC?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "# get text from the first 5 results\n",
    "print(f\"Found {results[0].page_content} relevant documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd57b355",
   "metadata": {},
   "source": [
    "## <p style=\"padding:50px;background-color:#06402B;margin:0;color:#fafefe;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:100\">Evaluation Functions</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d71658",
   "metadata": {},
   "source": [
    "### 1. Define Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9808af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(prediction: str, ground_truth: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute the token-level F1 score between prediction and ground_truth.\n",
    "    \"\"\"\n",
    "    pred_tokens = prediction.split()\n",
    "    gt_tokens = ground_truth.split()\n",
    "    common = Counter(pred_tokens) & Counter(gt_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0.0\n",
    "    precision = num_same / len(pred_tokens)\n",
    "    recall = num_same / len(gt_tokens)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "def evaluate_model(\n",
    "    predict_fn: Callable[[str, str], str],\n",
    "    data_path: Path,\n",
    "    max_rows: int = 50\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a model over the first `max_rows` entries of a JSONL file with fields: context, question, answers.text.\n",
    "    Returns average F1 score and number of samples evaluated.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    with data_path.open('r', encoding='utf-8') as f:\n",
    "        for line in itertools.islice(f, max_rows):\n",
    "            record = json.loads(line)\n",
    "            question = record.get('question', '')\n",
    "            docs = retriever.get_relevant_documents(question)\n",
    "            context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "            gold_texts = record.get('answers', {}).get('text', [])\n",
    "            \n",
    "            # get prediction\n",
    "            pred = predict_fn(question, context)\n",
    "            \n",
    "            # compute best F1 against all golds\n",
    "            if gold_texts:\n",
    "                sample_f1 = max(f1_score(pred, gt) for gt in gold_texts)\n",
    "            else:\n",
    "                sample_f1 = 0.0\n",
    "            scores.append(sample_f1)\n",
    "\n",
    "    num_samples = len(scores)\n",
    "    avg_f1 = sum(scores) / num_samples if num_samples else 0.0\n",
    "    return {\"average_f1\": avg_f1, \"num_samples\": num_samples}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1e8e2",
   "metadata": {},
   "source": [
    "## <p style=\"padding:50px;background-color:#06402B;margin:0;color:#fafefe;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:100\">LLM Model 1: Zero-Shot Google Gemini</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fef92",
   "metadata": {},
   "source": [
    "### 1. Define Model & API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0342a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"gemini-1.5-flash-8b\"\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e276bacc",
   "metadata": {},
   "source": [
    "### 2. Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3d76a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=MODEL_NAME,\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\",\n",
    "    output_key=\"output\",\n",
    "    return_messages=True,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[],  \n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a14e7",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"South Africa is a country located at the southern tip of Africa. It is known for its diverse culture, languages, and history. The country has a rich heritage and is famous for its wildlife, natural beauty, and landmarks such as Table Mountain and Kruger National Park.\"\n",
    "question = \"What is the capital of South Africa?\"\n",
    "result = agent.run(f\"Context: {context}\\nQuestion: {question}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfab46",
   "metadata": {},
   "source": [
    "### 3. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82aae9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model1(question: str, context: str) -> str:\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            prompt_input = f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
    "            result = agent.run(prompt_input)\n",
    "            return result\n",
    "        except ResourceExhausted as e:\n",
    "            wait = 60  # sleep long enough to clear the per-minute bucket\n",
    "            print(f\"Quota exceeded, sleeping for {wait}s… (attempt {attempt+1}/5)\")\n",
    "            time.sleep(wait)\n",
    "    raise RuntimeError(\"Max retries hit for model1 due to quota limits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaeb85af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model 1...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Denver Broncos\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Carolina Panthers\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Denver Broncos\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Gold\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Golden anniversary\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"February 7, 2016\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"American Football Conference\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Golden anniversary\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"American Football Conference\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"February 7, 2016\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Denver Broncos won Super Bowl 50.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Levi's Stadium\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Santa Clara, California\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Super Bowl L\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash-8b\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2015\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Quota exceeded, sleeping for 60s… (attempt 1/5)\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2015\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Santa Clara, California\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Levi's Stadium\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"24–10\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"February 7, 2016\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2015\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Denver Broncos\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Carolina Panthers\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Denver Broncos won Super Bowl 50.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2015\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Denver Broncos\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Levi's Stadium in the San Francisco Bay Area, Santa Clara, California\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Super Bowl\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Denver Broncos won the AFC playoffs in 2015.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Cam Newton\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash-8b\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"8\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Quota exceeded, sleeping for 60s… (attempt 1/5)\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"1995\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Carolina Panthers defeated the Arizona Cardinals.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The New England Patriots\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Arizona Cardinals\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The New England Patriots\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The New England Patriots\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Four teams: the Patriots, the Cowboys, the Steelers, and the Broncos.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Cam Newton\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"15-1\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Cam Newton\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"tool_code\",\n",
      "  \"action_input\": \"Search online for the 2015 Denver Broncos regular season win-loss record.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: tool_code is not a valid tool, try one of [].\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Denver Broncos had a 12-4 record in the 2015 regular season.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Four teams have played in the Super Bowl eight times: the Patriots, the Cowboys, the Steelers, and the Broncos.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The New England Patriots\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Cam Newton\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash-8b\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Carolina Panthers beat the Arizona Cardinals in the NFC Championship game.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Quota exceeded, sleeping for 60s… (attempt 1/5)\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Panthers have been to the Super Bowl two times.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The Denver Broncos beat the New England Patriots in the AFC Championship game.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"tool_code\",\n",
      "  \"action_input\": \"Search the internet for '2015 NFL MVP'\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: tool_code is not a valid tool, try one of [].\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Unfortunately, the provided context doesn't explicitly state who won the 2015 NFL MVP award.  It only mentions Cam Newton winning the award in a *different* year.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_file = Path('experiments/data/validation.json')\n",
    "print('Evaluating Model 1...')\n",
    "res1 = evaluate_model(predict_model1, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb35e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_f1': 0.7083780206721383, 'num_samples': 50}\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3b65c",
   "metadata": {},
   "source": [
    "## <p style=\"padding:50px;background-color:#06402B;margin:0;color:#fafefe;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:100\">LLM Model 2: Zero-Shot Finetuned LlaMa-3B-Instruct Model</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68650f8e",
   "metadata": {},
   "source": [
    "### 1. Load the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1956008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms.llama_3b_instruct_finetuned_llm import load_model, generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cb14226",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af0246bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert QA assistant. Use ReAct-style reasoning:\n",
    "- Start each step with \\\"Thought: <what you’re thinking>\\\"\n",
    "- If you would call a tool, write \\\"Action: <tool_name>(<input>)\\\" (no actual tool is run)\n",
    "- After reasoning, conclude with \\\"Final Answer: <your answer>\\\"\n",
    "\n",
    "Be sure to:\n",
    "1. Show your chain-of-thought step by step.\n",
    "2. Then output exactly one \\\"Final Answer:\\\" line with the answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e626f",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07fd3baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ('Paris')\n",
      "\n",
      "    ### Output: \n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "    Final Answer: Paris\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input =  \"What is the capital of France?\",\n",
    "context = \"The capital of France is Paris.\"\n",
    "\n",
    "final_answer: str = generate_response(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    context=context,\n",
    "    question=input,\n",
    "    system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc92a5",
   "metadata": {},
   "source": [
    "### 2. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1c1c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"context\", \"chat_history\"],\n",
    "    template=\"\"\"\n",
    "### Instructions\n",
    "You are an expert QA assistant. You must think through the reasoning step-by-step (chain-of-thought) before giving the final answer. Show your intermediate reasoning clearly.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### User question:\n",
    "{input}\n",
    "\n",
    "### Reasoning (think step-by-step):\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4f07fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model2(question: str, context: str) -> str:\n",
    "    result = generate_response(model=model, tokenizer=tokenizer, context=context, question=question, system_prompt=PROMPT)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba89b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model 2...\n",
      "{'average_f1': 0.10473273657113578, 'num_samples': 50}\n"
     ]
    }
   ],
   "source": [
    "data_file = Path('experiments/data/validation.json')\n",
    "print('Evaluating Model 2...')\n",
    "res2 = evaluate_model(predict_model2, data_file)\n",
    "print(res2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
